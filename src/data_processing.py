import os
import re
import hashlib
import time
from pypdf import PdfWriter, PdfReader
from unstructured.partition.pdf import partition_pdf
from PIL import Image
import google.generativeai as genai

# Importa as configura√ß√µes
from src.config import RAW_DATA_DIR, PROCESSED_DATA_DIR, IMAGE_DIR, GOOGLE_API_KEY

# Configura a API do Gemini
try:
    genai.configure(api_key=GOOGLE_API_KEY)
except Exception as e:
    print(f"Erro ao configurar a API do Google Generative AI: {e}")

model = genai.GenerativeModel('models/gemini-1.5-pro-latest')

def limpar_pdf(nome_arquivo_original, nome_arquivo_saida, paginas_a_manter):
    # (Esta fun√ß√£o permanece inalterada)
    caminho_original = os.path.join(RAW_DATA_DIR, nome_arquivo_original)
    caminho_saida = os.path.join(PROCESSED_DATA_DIR, nome_arquivo_saida)
    os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)
    reader = PdfReader(caminho_original)
    writer = PdfWriter()
    for i in paginas_a_manter:
        if i < len(reader.pages):
            writer.add_page(reader.pages[i])
    with open(caminho_saida, "wb") as f:
        writer.write(f)
    print(f"PDF limpo salvo em: {caminho_saida}")
    return caminho_saida

def extrair_elementos_do_manual(caminho_pdf_processado, nome_projeto):
    # (Esta fun√ß√£o permanece inalterada)
    print(f"Iniciando a extra√ß√£o do arquivo: {caminho_pdf_processado}")
    pasta_imagens = os.path.join(IMAGE_DIR, nome_projeto)
    os.makedirs(pasta_imagens, exist_ok=True)
    elementos = partition_pdf(
        filename=caminho_pdf_processado, 
        strategy="hi_res",
        chunking_strategy="by_title",
        extract_images_in_pdf=True, 
        infer_table_structure=True,
        languages=["por"], 
        extract_image_block_output_dir=pasta_imagens,
    )
    print(f"Extra√ß√£o conclu√≠da. {len(elementos)} elementos brutos encontrados.")
    return elementos

def gerar_resumo(conteudo, tipo_conteudo):
    prompt_base = {
        "imagem": """
        Voc√™ √© um engenheiro biom√©dico especialista em equipamentos hospitalares. 
        Sua tarefa √© analisar a imagem de um manual de bomba de infus√£o e descrev√™-la em detalhes t√©cnicos precisos.
        Descreva todos os componentes vis√≠veis, como bot√µes, tela, indicadores LED, conex√µes e s√≠mbolos. 
        Se houver texto na imagem, transcreva-o. 
        Seja minucioso para que esta descri√ß√£o possa ser usada para responder a perguntas t√©cnicas sobre o equipamento.
        """,
        "tabela": """
        Voc√™ √© um analista de dados especialista em documenta√ß√£o t√©cnica.
        Sua tarefa √© analisar a seguinte tabela (em formato HTML) extra√≠da de um manual de bomba de infus√£o.
        N√£o resuma nada, As tabelas s√£o instru√ß√µes tecnicas e exatas. O objetivo √© que este resumo textual represente fielmente os dados da tabela para buscas futuras.
        """
    }

    if tipo_conteudo == "imagem":
        prompt = prompt_base["imagem"]
        img = Image.open(conteudo)
        response = model.generate_content([prompt, img])
    elif tipo_conteudo == "tabela":
        prompt = prompt_base["tabela"]
        response = model.generate_content(f"{prompt}\n\nAqui est√° a tabela em HTML:\n{conteudo}")
    else:
        return ""
    return response.text

def calcular_hash_imagem(caminho_imagem):
    # (Esta fun√ß√£o permanece inalterada)
    sha256_hash = hashlib.sha256()
    with open(caminho_imagem, "rb") as f:
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    return sha256_hash.hexdigest()

# ==============================================================================
# FUN√á√ÉO DE AGRUPAMENTO SEM√ÇNTICO (VERS√ÉO ROBUSTA)
# ==============================================================================
def agrupar_elementos_por_secao(elementos):
    """
    Agrupa elementos extra√≠dos em chunks sem√¢nticos baseados nos t√≠tulos das se√ß√µes,
    de forma robusta e independente da categoriza√ß√£o do 'unstructured'.
    """
    # Regex para identificar t√≠tulos de se√ß√£o (ex: "1.2", "5.3.1", "Ap√™ndice A")
    padrao_titulo = re.compile(r'^\d+(\.\d+)*\s|\bAP√äNDICE\s[A-Z]\b', re.IGNORECASE)
    
    secoes_agrupadas = []
    chunk_atual = None
    hashes_de_imagens_vistas = set()
    
    print("\n--- üîÑ Iniciando o agrupamento sem√¢ntico por se√ß√µes (Estrat√©gia Robusta)... ---")
    
    total_elementos = len(elementos)
    for i, el in enumerate(elementos):
        
        # Ignora elementos sem texto, a menos que sejam imagens
        if not hasattr(el, 'text') or not el.text.strip():
            if el.category != "Image":
                continue

        texto_elemento = el.text if hasattr(el, 'text') else ''

        # ==========================================================
        # L√ìGICA DE IDENTIFICA√á√ÉO DE T√çTULO CORRIGIDA E ROBUSTA
        # ==========================================================
        # Se o texto do elemento corresponde ao nosso padr√£o de t√≠tulo E √© curto o suficiente,
        # n√≥s o TRATAMOS como um t√≠tulo, n√£o importa sua categoria.
        e_titulo = padrao_titulo.match(texto_elemento) and len(texto_elemento) < 150
        # ==========================================================

        if e_titulo:
            if chunk_atual:
                secoes_agrupadas.append(chunk_atual)
            
            print(f"\n[+] Nova Se√ß√£o Encontrada: {texto_elemento.strip()}")
            chunk_atual = {
                "titulo_secao": texto_elemento.strip(),
                "conteudo_combinado": f"IN√çCIO DA SE√á√ÉO: {texto_elemento.strip()}\n\n",
                "paginas": {el.metadata.page_number} if hasattr(el.metadata, 'page_number') else set()
            }
            # Se o t√≠tulo tamb√©m for um texto narrativo, adiciona ao conte√∫do
            if el.category == "NarrativeText":
                 chunk_atual["conteudo_combinado"] += texto_elemento + "\n"

        elif chunk_atual:
            conteudo_para_adicionar = ""
            
            if "Text" in el.category:
                conteudo_para_adicionar = texto_elemento
            
            elif el.category == "Table":
                pagina = el.metadata.page_number if hasattr(el.metadata, 'page_number') else 'N/A'
                print(f"    -> üìä Tabela encontrada na p√°g. {pagina}. Gerando resumo via API...")
                resumo_tabela = gerar_resumo(el.metadata.text_as_html, "tabela")
                conteudo_para_adicionar = f"\n--- IN√çCIO DA TABELA ---\n{resumo_tabela}\n--- FIM DA TABELA ---\n"
                print("       - Resumo da tabela conclu√≠do.")
                time.sleep(2)

            elif el.category == "Image":
                pagina = el.metadata.page_number if hasattr(el.metadata, 'page_number') else 'N/A'
                print(f"    -> üñºÔ∏è Imagem encontrada na p√°g. {pagina}. Analisando...")
                caminho_imagem = el.metadata.image_path
                hash_atual = calcular_hash_imagem(caminho_imagem)
                
                if hash_atual in hashes_de_imagens_vistas:
                    print("       - Imagem duplicada. Ignorando.")
                else:
                    print("       - Imagem √öNICA. Gerando resumo via API...")
                    hashes_de_imagens_vistas.add(hash_atual)
                    resumo_imagem = gerar_resumo(caminho_imagem, "imagem")
                    conteudo_para_adicionar = f"\n--- DESCRI√á√ÉO DA IMAGEM ---\n{resumo_imagem}\n--- FIM DA DESCRI√á√ÉO ---\n"
                    print("       - Resumo da imagem conclu√≠do.")
                    time.sleep(2)

            if conteudo_para_adicionar:
                chunk_atual["conteudo_combinado"] += conteudo_para_adicionar + "\n"
                if hasattr(el.metadata, 'page_number'):
                    chunk_atual["paginas"].add(el.metadata.page_number)

    if chunk_atual:
        secoes_agrupadas.append(chunk_atual)

    print(f"\n--- ‚úÖ Agrupamento conclu√≠do. {len(secoes_agrupadas)} se√ß√µes sem√¢nticas foram criadas. ---")
    return secoes_agrupadas